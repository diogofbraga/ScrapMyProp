{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap My Prop\n",
    "\n",
    "### Laboratórios de Engenharia Informática\n",
    "\n",
    "**\"Development of an IT solution for the extraction and automatic analysis of data and relevant information for the calculation of land and properties.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from IPython.core.debugger import set_trace\n",
    "import geopy.distance\n",
    "import os.path\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparationData(data_imo):\n",
    "    data_imo = data_imo[['Id','Preço']]\n",
    "    \n",
    "    data_imo = data_imo.dropna(subset=['Id'])\n",
    "    data_imo.index = np.arange(1, len(data_imo) + 1)\n",
    "    \n",
    "    data_imo['Id'] = data_imo['Id'].astype(int)\n",
    "    \n",
    "    return data_imo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toNumeric(string):\n",
    "    res = str(string)\n",
    "    res = res.replace(\" \", \"\")\n",
    "    res = res.replace(\",\", \".\")\n",
    "    res = float(pd.to_numeric(res, errors='ignore')) # tem que ser float porque esse tipo consegue interpretar o np.nan\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparationPreco(data_imo):\n",
    "\n",
    "    data_imo['Preço'] = data_imo['Preço'].apply(toNumeric)\n",
    "\n",
    "    nan_prices = data_imo['Preço'].index[data_imo['Preço'].apply(np.isnan)]\n",
    "    data_imo = data_imo.drop(nan_prices)\n",
    "    data_imo.index = np.arange(1, len(data_imo) + 1)\n",
    "\n",
    "    data_imo['Preço'] = data_imo['Preço'].apply(int)\n",
    "    \n",
    "    return data_imo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imovel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imovel():\n",
    "    def getData(self):\n",
    "        return self.datas\n",
    "\n",
    "    def getPreco(self):\n",
    "        return self.precos\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.datas = []\n",
    "        self.precos = []\n",
    "        self.previsoes=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imoveis = {}\n",
    "\n",
    "for mes in range(4,7):\n",
    "    if mes > 0 and mes < 10:\n",
    "        mes = str(mes).zfill(2)\n",
    "    print(\"------ Mês:\", mes)\n",
    "    for dia in range(1,31):\n",
    "        if dia > 0 and dia < 10:\n",
    "            dia = str(dia).zfill(2)\n",
    "        print(\"--- Dia:\", dia)\n",
    "        if os.path.isfile(f'../dados/dados_imovirtual_{dia}_{mes}.csv'):\n",
    "            data_imo = pd.read_csv(f'../dados/dados_imovirtual_{dia}_{mes}.csv', engine='python', encoding='utf8')\n",
    "            data_imo = preparationData(data_imo)\n",
    "            data_imo = preparationPreco(data_imo)\n",
    "            print(data_imo.shape)\n",
    "            for index, row in data_imo.iterrows():\n",
    "                #imovel = Imovel(f'{dia}/{mes}', row['Preço'])\n",
    "                if row['Id'] not in imoveis:\n",
    "                    imoveis[row['Id']] = Imovel()\n",
    "                imoveis[row['Id']].datas.append(f'{dia}/{mes}')\n",
    "                imoveis[row['Id']].precos.append(row['Preço'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imoveis.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(imoveis.get(11160514).datas)\n",
    "imoveis.get(11160514).precos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in imoveis.items():\n",
    "    dif = v.precos[-1]-v.precos[0]\n",
    "    if abs(dif) > 10000:\n",
    "        print(k, dif, set(v.precos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(imoveis.get(11160514).datas, imoveis.get(11160514).precos, 'go--', linewidth=2, markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k,v in imoveis.items():\n",
    "#    print(\"chave \", k, \" com os valores \", v.getPreco())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in imoveis.items():\n",
    "    print(len(v.precos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "for k,v in imoveis.items():\n",
    "    if len(v.precos)>3: # por alguma razão tem de ser >3\n",
    "        model=AutoReg(v.precos, lags=1)\n",
    "        history = model.fit()\n",
    "        predictions=history.predict(len(v.precos),len(v.precos)+7)\n",
    "        v.previsoes=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_preco = [*imoveis.get(11160514).precos, *imoveis.get(11160514).previsoes]\n",
    "arr_data = [*imoveis.get(11160514).datas, *range(0,len(imoveis.get(11160514).previsoes))]\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(arr_data, arr_preco, 'go--', linewidth=2, markersize=12)\n",
    "plt.show()\n",
    "print(imoveis.get(11160514).precos)\n",
    "print(imoveis.get(11160514).previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "for k,v in imoveis.items():\n",
    "    if len(v.precos)>1:\n",
    "        model = SimpleExpSmoothing(v.precos)\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        predictions = model_fit.predict(len(v.precos), len(v.precos)+7)\n",
    "        v.previsoes=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_preco = [*imoveis.get(11160514).precos, *imoveis.get(11160514).previsoes]\n",
    "arr_data = [*imoveis.get(11160514).datas, *range(0,len(imoveis.get(11160514).previsoes))]\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(arr_data, arr_preco, 'go--', linewidth=2, markersize=12)\n",
    "plt.show()\n",
    "print(imoveis.get(11160514).precos)\n",
    "print(imoveis.get(11160514).previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holt Winter’s Exponential Smoothing/Triple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "for k,v in imoveis.items():\n",
    "    if len(v.precos)>1:\n",
    "        model = ExponentialSmoothing(v.precos)\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        predictions = model_fit.predict(len(v.precos), len(v.precos)+7)\n",
    "        v.previsoes=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_preco = [*imoveis.get(11160514).precos, *imoveis.get(11160514).previsoes]\n",
    "arr_data = [*imoveis.get(11160514).datas, *range(0,len(imoveis.get(11160514).previsoes))]\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(arr_data, arr_preco, 'go--', linewidth=2, markersize=12)\n",
    "plt.show()\n",
    "print(imoveis.get(11160514).precos)\n",
    "print(imoveis.get(11160514).previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede LSTM (não apropriada para este tipo de problema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pdb\n",
    "timesteps=5 #linhas usadas para prever o(s) proximo(s) valor(es)\n",
    "multisteps=1 #número de linhas que irá prever\n",
    "features=1 #nº variáveis usadas para prever os próximos valores\n",
    "batch_size=8\n",
    "\n",
    "X,y=list(),list()\n",
    "dataset_size=len(imoveis.get(15386584).precos)\n",
    "for curr_pos in range(dataset_size):\n",
    "    input_index=curr_pos+timesteps\n",
    "    label_index=input_index+multisteps\n",
    "    if label_index<dataset_size:\n",
    "        X.append(imoveis.get(15386584).precos[curr_pos:input_index])\n",
    "        y.append(imoveis.get(15386584).precos[input_index:label_index])\n",
    "X=np.reshape(np.array(X),(len(X),timesteps,features))\n",
    "y=np.reshape(np.array(y),(len(y),multisteps))\n",
    "drop=0.2\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, return_sequences=True, input_shape=(timesteps,features)))\n",
    "model.add(tf.keras.layers.Dropout(drop))\n",
    "model.add(tf.keras.layers.LSTM(256, return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(drop))\n",
    "model.add(tf.keras.layers.LSTM(256, return_sequences=True))\n",
    "#model.add(tf.keras.layers.Dropout(drop))\n",
    "#model.add(tf.keras.layers.LSTM(256, return_sequences=True))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(multisteps, activation = 'relu'))\n",
    "model.compile(\n",
    "    loss= tf.keras.losses.mae,\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    metrics=['MeanSquaredError'])\n",
    "stepsper = X.shape[0]/batch_size\n",
    "history=model.fit(X, y, shuffle=False, epochs=200, verbose=1, steps_per_epoch = stepsper, batch_size = batch_size)\n",
    "predictions=model.predict(X)\n",
    "imoveis.get(15386584).previsoes = predictions\n",
    "print(imoveis.get(15386584).precos)\n",
    "print(imoveis.get(15386584).previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pdb\n",
    "timesteps=3 #linhas usadas para prever o(s) proximo(s) valor(es)\n",
    "multisteps=1 #número de linhas que irá prever\n",
    "features=1 #nº variáveis usadas para prever os próximos valores\n",
    "batch_size=8\n",
    "\n",
    "for k,v in imoveis.items():\n",
    "    if len(v.precos)>timesteps:\n",
    "        X,y=list(),list()\n",
    "        dataset_size=len(v.precos)\n",
    "        for curr_pos in range(dataset_size):\n",
    "            input_index=curr_pos+timesteps\n",
    "            label_index=input_index+multisteps\n",
    "            if label_index<dataset_size:\n",
    "                X.append(v.precos[curr_pos:input_index])\n",
    "                y.append(v.precos[input_index:label_index])\n",
    "        X=np.reshape(np.array(X),(len(X),timesteps,features))\n",
    "        y=np.reshape(np.array(y),(len(y),multisteps))\n",
    "        drop=0.2\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.LSTM(16, return_sequences=True, input_shape=(timesteps,features)))\n",
    "        #model.add(tf.keras.layers.Dropout(drop))\n",
    "        #model.add(tf.keras.layers.LSTM(16, return_sequences=True))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(multisteps, activation = 'relu'))\n",
    "        model.compile(\n",
    "            loss= tf.keras.losses.mae,\n",
    "            optimizer= tf.keras.optimizers.Adam(),\n",
    "            metrics=['MeanSquaredError'])\n",
    "        stepsper = X.shape[0]/batch_size\n",
    "        history=model.fit(X, y, shuffle=False, epochs=50, verbose=0, steps_per_epoch = stepsper, batch_size = batch_size)\n",
    "        predictions=model.predict(X)\n",
    "        imoveis.get(k).previsoes = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pdb\n",
    "timesteps=3 #linhas usadas para prever o(s) proximo(s) valor(es)\n",
    "multisteps=1 #número de linhas que irá prever\n",
    "features=1 #nº variáveis usadas para prever os próximos valores\n",
    "batch_size=8\n",
    "drop=0.3\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(512, return_sequences=True, input_shape=(timesteps,features)))\n",
    "model.add(tf.keras.layers.Dropout(drop))\n",
    "model.add(tf.keras.layers.LSTM(512, return_sequences=True))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(multisteps, activation = 'relu'))\n",
    "model.compile(\n",
    "    loss= tf.keras.losses.mae,\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    metrics=[])\n",
    "\n",
    "for k,v in imoveis.items():\n",
    "    if len(v.precos)>batch_size:\n",
    "        X,y=list(),list()\n",
    "        dataset_size=len(v.precos)\n",
    "        for curr_pos in range(dataset_size):\n",
    "            input_index=curr_pos+timesteps\n",
    "            label_index=input_index+multisteps\n",
    "            if label_index<dataset_size:\n",
    "                X.append(v.precos[curr_pos:input_index])\n",
    "                y.append(v.precos[input_index:label_index])\n",
    "        X=np.reshape(np.array(X),(len(X),timesteps,features))\n",
    "        y=np.reshape(np.array(y),(len(y),multisteps))\n",
    "        stepsper = X.shape[0]/batch_size\n",
    "        history=model.fit(X, y, shuffle=False, epochs=10, verbose=0, steps_per_epoch = stepsper, batch_size = batch_size)\n",
    "        predictions=model.predict(X)\n",
    "        imoveis.get(k).previsoes = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imoveis.get(15324144).precos)\n",
    "print(imoveis.get(15324144).previsoes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
